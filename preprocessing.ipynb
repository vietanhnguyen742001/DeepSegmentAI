{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def update_filename(image, max_id_length):\n",
    "    \"\"\"Update the filename using zero-padding.\"\"\"\n",
    "    # Extract the file extension\n",
    "    _, ext = image['file_name'].rsplit('.', 1)\n",
    "    # Update the file name using the image id with proper zero-padding\n",
    "    formatted_id = f\"{(image['id'] - 1):0{max_id_length}d}\"\n",
    "    image['file_name'] = f\"{formatted_id}.{ext}\"\n",
    "\n",
    "\n",
    "def merge_annotations(annotations1, annotations2):\n",
    "    \"\"\"Merge two sets of annotations.\"\"\"\n",
    "    # Calculate the maximum IDs from the first dataset\n",
    "    max_image_id = max(image['id'] for image in annotations1['images'])\n",
    "    max_annotation_id = max(anno['id'] for anno in annotations1['annotations'])\n",
    "\n",
    "    # Determine the max ID length for zero-padding filenames, considering the total number of images after merging\n",
    "    total_image_count = len(annotations1['images']) + len(annotations2['images'])\n",
    "    max_id_length = len(str(total_image_count - 1))  # Adjust for zero-padding to match the largest ID\n",
    "\n",
    "    # Update IDs and filenames in the second dataset\n",
    "    for image in annotations2['images']:\n",
    "        image['id'] += max_image_id\n",
    "        update_filename(image, max_id_length)\n",
    "\n",
    "    for annotation in annotations2['annotations']:\n",
    "        annotation['id'] += max_annotation_id\n",
    "        annotation['image_id'] += max_image_id\n",
    "\n",
    "    # Merge the images, annotations, and keep categories from the first dataset unchanged\n",
    "    merged_annotations = {\n",
    "        \"images\": annotations1['images'] + annotations2['images'],\n",
    "        \"annotations\": annotations1['annotations'] + annotations2['annotations'],\n",
    "        \"categories\": annotations1['categories']  # Assuming categories do not need to be merged\n",
    "    }\n",
    "    return merged_annotations\n",
    "\n",
    "\n",
    "# File paths for input and output\n",
    "input_file1 = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\train\\\\_annotations.coco.json'\n",
    "input_file2 = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\val\\\\_annotations.coco.json'\n",
    "output_file = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json'\n",
    "\n",
    "# Load annotations from files\n",
    "with open(input_file1, 'r') as file:\n",
    "    annotations_cable = json.load(file)\n",
    "\n",
    "with open(input_file2, 'r') as file:\n",
    "    annotations_capacitor = json.load(file)\n",
    "\n",
    "# Merge annotations and save to a new file\n",
    "merged_annotations = merge_annotations(annotations_cable, annotations_capacitor)\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(merged_annotations, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ids_in_coco_json(file_path, output_path, increment=1792):\n",
    "    \"\"\"Update image and annotation IDs in a COCO JSON file.\"\"\"\n",
    "    # Load the existing data\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Update 'id' in 'images'\n",
    "    for image in data['images']:\n",
    "        image['id'] += increment\n",
    "    \n",
    "    # Update 'id' and 'image_id' in 'annotations'\n",
    "    for annotation in data['annotations']:\n",
    "        annotation['id'] += increment\n",
    "        annotation['image_id'] += increment\n",
    "    \n",
    "    # Save the updated data\n",
    "    with open(output_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "update_ids_in_coco_json(\n",
    "    'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json',\n",
    "    'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_images(folder_path, start_index):\n",
    "    \"\"\"Rename images in a folder with incremental index starting from start_index.\"\"\"\n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Sort the files in numerical order\n",
    "    files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    # Initialize index starting from start_index\n",
    "    index = start_index\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for filename in files:\n",
    "        # Get the extension of the file\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        # Create a new filename\n",
    "        new_filename = str(index) + ext\n",
    "        new_file_path = os.path.join(folder_path, new_filename)\n",
    "        old_file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if the new filename already exists\n",
    "        if not os.path.exists(new_file_path):\n",
    "            # Rename the file\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "        else:\n",
    "            print(f\"Error: '{new_filename}' already exists.\")\n",
    "\n",
    "        # Increment the index\n",
    "        index += 1\n",
    "\n",
    "# Update this path to your folder path\n",
    "folder_path = \"E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\data\"\n",
    "start_index = 1793\n",
    "rename_images(folder_path, start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_file_names(json_file):\n",
    "    \"\"\"Update file names of images in a JSON file based on their IDs.\"\"\"\n",
    "    # Read the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Update the file_name of images\n",
    "    for image in data['images']:\n",
    "        image['file_name'] = f\"{image['id']}.jpg\"  # Update file_name based on id\n",
    "\n",
    "    # Write the updated data to a new file\n",
    "    output_file_path = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json'\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Call the function with the path to the annotations file\n",
    "json_file_path = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json'\n",
    "update_file_names(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "annotation_file = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\_annotations.coco.json'\n",
    "image_directory = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\data'\n",
    "\n",
    "# Define output directories\n",
    "train_dir = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\data\\\\train'\n",
    "val_dir = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\data\\\\val'\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Shuffle images\n",
    "image_list = data['images']\n",
    "random.shuffle(image_list)\n",
    "\n",
    "# Calculate split indices\n",
    "total_images = len(image_list)\n",
    "train_end = int(total_images * 0.8)  # Adjusted to 80% for training\n",
    "\n",
    "# Split image list\n",
    "train_images = image_list[:train_end]\n",
    "val_images = image_list[train_end:]  # All remaining images for validation\n",
    "\n",
    "# Function to create datasets\n",
    "def create_dataset(images, annotations, categories, output_dir):\n",
    "    \"\"\"Create dataset and save JSON annotations.\"\"\"\n",
    "    dataset = {\n",
    "        'images': images,\n",
    "        'annotations': [ann for ann in annotations if ann['image_id'] in [img['id'] for img in images]],\n",
    "        'categories': categories\n",
    "    }\n",
    "    # Save dataset to JSON\n",
    "    json_file_path = os.path.join(output_dir, '_annotations.coco.json')\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(dataset, f, indent=4)\n",
    "    \n",
    "    # Copy images to their respective folders\n",
    "    for image in images:\n",
    "        source_path = os.path.join(image_directory, image['file_name'])\n",
    "        destination_path = os.path.join(output_dir, image['file_name'])\n",
    "        try:\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {source_path}\")\n",
    "\n",
    "# Create and save datasets\n",
    "create_dataset(train_images, data['annotations'], data['categories'], train_dir)\n",
    "create_dataset(val_images, data['annotations'], data['categories'], val_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_json(file_path1, file_path2, output_file_path):\n",
    "    \"\"\"Merge two JSON files and save the combined data to a new JSON file.\"\"\"\n",
    "    # Load data from the first JSON file\n",
    "    with open(file_path1, 'r') as file1:\n",
    "        data1 = json.load(file1)\n",
    "    \n",
    "    # Load data from the second JSON file\n",
    "    with open(file_path2, 'r') as file2:\n",
    "        data2 = json.load(file2)\n",
    "    \n",
    "    # Merge images\n",
    "    images = data1[\"images\"] + data2[\"images\"]\n",
    "    \n",
    "    # Merge annotations\n",
    "    annotations = data1[\"annotations\"] + data2[\"annotations\"]\n",
    "    \n",
    "    # Merge categories (assuming categories are identical in both files)\n",
    "    categories = data1[\"categories\"]  + data2[\"categories\"]\n",
    "    \n",
    "    # Combine all data into a new dictionary\n",
    "    combined_data = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": categories\n",
    "    }\n",
    "    \n",
    "    # Write the combined data to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        json.dump(combined_data, output_file, indent=4)\n",
    "    \n",
    "    print(f\"Combined JSON has been saved to {output_file_path}\")\n",
    "\n",
    "# Paths to the input JSON files and the output JSON file\n",
    "file_path1 = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\val\\\\_annotations.json'\n",
    "file_path2 = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\Wood\\\\data\\\\val\\\\_annotations.coco.json'\n",
    "output_file_path = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\val\\\\_annotations.json'\n",
    "\n",
    "# Merge the JSON files\n",
    "merge_json(file_path1, file_path2, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jpg_images(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of .jpg files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory where the images are stored.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of .jpg files in the directory.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory not found: {directory}\")\n",
    "        return 0\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Filter and count files that end with .jpg\n",
    "    jpg_count = sum(1 for file in files if file.lower().endswith('.jpg'))\n",
    "\n",
    "    return jpg_count\n",
    "\n",
    "# Example usage:\n",
    "directory_path = 'E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\val'\n",
    "jpg_count = count_jpg_images(directory_path)\n",
    "print(f\"There are {jpg_count} .jpg files in the directory {directory_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filecmp\n",
    "\n",
    "def find_duplicate_images(folder1, folder2):\n",
    "    \"\"\"\n",
    "    Finds duplicate images between two folders.\n",
    "\n",
    "    Args:\n",
    "        folder1 (str): The path to the first folder.\n",
    "        folder2 (str): The path to the second folder.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of duplicate image filenames.\n",
    "    \"\"\"\n",
    "    # Create lists containing image files from both folders\n",
    "    images1 = [f for f in os.listdir(folder1) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    images2 = [f for f in os.listdir(folder2) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Create a directory comparison object\n",
    "    dcmp = filecmp.dircmp(folder1, folder2)\n",
    "\n",
    "    # Create a list to store duplicate images\n",
    "    duplicate_images = []\n",
    "\n",
    "    # Compare image files in the directories\n",
    "    for common_file in dcmp.common_files:\n",
    "        if common_file in images1 and common_file in images2:\n",
    "            file1 = os.path.join(folder1, common_file)\n",
    "            file2 = os.path.join(folder2, common_file)\n",
    "            if filecmp.cmp(file1, file2):\n",
    "                duplicate_images.append(common_file)\n",
    "\n",
    "    return duplicate_images\n",
    "\n",
    "# Example usage\n",
    "folder1 = \"E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\train\"\n",
    "folder2 = \"E:\\\\research2024\\\\VISION-Datasets - Copy\\\\VISION-Datasets extracted\\\\val\"\n",
    "duplicates = find_duplicate_images(folder1, folder2)\n",
    "if duplicates:\n",
    "    print(\"The following images are duplicates:\")\n",
    "    for image in duplicates:\n",
    "        print(image)\n",
    "else:\n",
    "    print(\"No duplicate images found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
